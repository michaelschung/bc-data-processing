{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The DataFrame Data Structure\n",
    "\n",
    "A **DataFrame** is the primary object that we'll be using for cleaning and analyzing structured data sets. We can think of a DataFrame as essentially a 2-dimensional Series, or as a table with labeled rows and columns.\n",
    "\n",
    "There are many ways to create a DataFrame. For example, we can use a group of series, where each Series represents a row of data. We could also use a group of dictionaries, where each dictionary represents a row of data. For now, let's use the first method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three Series with the same indexes\n",
    "purchase_1 = pd.Series({'Name': 'Mr. Chung',\n",
    "                        'Item': 'Dog Food',\n",
    "                        'Cost': 22.50})\n",
    "purchase_2 = pd.Series({'Name': 'Mr. Gaines',\n",
    "                        'Item': 'Kitty Litter',\n",
    "                        'Cost': 2.50})\n",
    "purchase_3 = pd.Series({'Name': 'Mr. Lucey',\n",
    "                        'Item': 'Bird Seed',\n",
    "                        'Cost': 5.00})\n",
    "\n",
    "# Combine Series into a DataFrame, setting index values indicating where each purchase occurred\n",
    "df = pd.DataFrame([purchase_1, purchase_2, purchase_3], index=['Store 1', 'Store 1', 'Store 2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data\n",
    "We can extract data from the DataFrame using the `loc` and `iloc` attributes, just like with a Series. When we use these attributes on a DataFrame, we query for a specific *row* as given by the index label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows: Store 2\n",
    "# Cols: (all)\n",
    "df.loc['Store 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the object returned is a Series, since there was only one row corresponding to the index `Store 2`. We can verify this using the Python `type()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.loc['Store 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are multiple matching rows, then the result is returned as another DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows: Store 1\n",
    "# Cols: (all)\n",
    "df.loc['Store 1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame object allows us to easily select data based on multiple axes. For example, if we want to list all of the costs for `Store 1`, all we have to do is supply two parameters to the `loc` attribute: the row name and the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows: Store 1\n",
    "# Cols: Cost\n",
    "df.loc['Store 1', 'Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to select an entire column, such as all of the costs? This may seem tricky, because every `loc` or `iloc` query must start with a row index. However, Pandas provides some ways around this.\n",
    "\n",
    "The first way takes advantage of the **transpose** of the DataFrame, which is what we call the same data with the rows and columns flipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking the transpose of `df`, we make it so that `Cost` is its own row; then, we can simply query using the `loc` attribute as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows: Cost\n",
    "# Cols: (all)\n",
    "df.T.loc['Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is a little bit ugly, so Pandas provides an even easier way! Since `loc` and `iloc` query by row, the operation of indexing directly on a DataFrame is reserved for querying by column. Columns always have names, so this will never cause a problem like it might with a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows: (all)\n",
    "# Cols: Cost\n",
    "df['Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since querying a DataFrame returns either a Series or another DataFrame, we can **chain** operations together. Here's another way we could have queried for all `Store 1` costs, using operation chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows: Store 1\n",
    "# Cols: Cost\n",
    "df.loc['Store 1']['Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note:** chaining is great, but be careful about when you use it! Chaining causes Pandas to return a *copy* of the DataFrame instead of a *view* of the original, and is thus slower and more memory-intensive than necessary.\n",
    "\n",
    "For the purposes of this course, the larger issue will be the fact that chaining returns a copy. In the future, when we start changing data values, it's important that we know the difference between editing a DataFrame and editing a copy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting and Slicing\n",
    "As we saw before, `loc` can take two parameters: a row index and a column name. We can also provide a list of column names to select. For example, let's select the `Name` and `Cost` for every purchase at `Store 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's report df again to remind ourselves of what it looks like\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows: Store 1\n",
    "# Cols: Name, Cost\n",
    "df.loc['Store 1', ['Name', 'Cost']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `loc` operator also supports slicing, for both rows and columns. For example, if we wanted to select the `Name` and `Cost` for every row, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows: (all)\n",
    "# Cols: Name, Cost\n",
    "df.loc[:, ['Name', 'Cost']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one more example of slicing, let's select all rows, but only the columns starting from `Item` and moving to the right (a.k.a. `Item` and `Cost`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows: (all)\n",
    "# Cols: Item, Cost\n",
    "df.loc[:, 'Item':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping and adding data\n",
    "To delete data from a DataFrame (or from a Series), we use the `drop()` function. But before we do that, let's remind ourselves of what our original DataFrame looks like, so that we can see the difference after dropping data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove a row, we simply call `drop()` and pass in the label of the row to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Store 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `drop()` method does not change the original DataFrame, but rather returns a copy in which the specified rows have been removed. We can verify this by taking another look at our original DataFrame â€“ nothing has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To store the copy with removed rows, we must store the result in a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df = df.drop('Store 1')\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove a specified column by passing in an optional parameter `axis=1`, which tells Pandas that the label should apply to columns instead of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_2 = df.drop('Item', axis=1)\n",
    "copy_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to remove a column is to index the DataFrame directly (which, remember, returns a column) and combine it with the `del` keyword. This will change the DataFrame directly without creating a copy, but it will not return a view of the updated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del copy_df['Name']\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can easily add a new column to a DataFrame. For example, if we want to add a new column `Location` with default values of `None`, we can do it as follows. Note that the value `None` gets broadcasted across all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location'] = None\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wish to specify a separate value for each row, we can do that using a list of the values to assign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location'] = ['Brooklyn', 'Brooklyn', 'Manhattan']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Indexing and Loading\n",
    "\n",
    "A common workflow is to read your data into a DataFrame, and then reduce that DataFrame into the specific columns or rows that you're interested in working with.\n",
    "\n",
    "## DataFrame views vs. copies\n",
    "When used properly, DataFrame queries give you a *view* of the data being accessed. This is much faster and more memory efficient than copying data. But this also means that you will have to be careful to keep track of which types of operations change a DataFrame in place, so that you always know the state of the DataFrame at any given point in time.\n",
    "\n",
    "Here's an example of an operation that changes the underlying DataFrame. Using the same purchasing data as before, we create a Series out of the `Cost` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = df['Cost']\n",
    "costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use broadcasting to increment every value in the Series by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs += 2\n",
    "costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you might not expect is that this actually changes the values in the original DataFrame as well. This is because querying the `Cost` column out of the DataFrame returned a *view* (a.k.a. not a copy) of the original, so any changes applied to that view are also applied to the underlying DataFrame.\n",
    "\n",
    "We can verify that the change has happened to the original data by taking another look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and indexing CSV files\n",
    "\n",
    "We'll be working a lot with moderately-sized data sets, which are often stored externally in what we call \"Comma-Separated Values\" (CSV) files. In order to work with such a data set, we must first read the file into a DataFrame.\n",
    "\n",
    "Here's an example of [a CSV file](https://raw.githubusercontent.com/michaelschung/bc-data-processing/master/datasets/zoo.csv), which contains data summarizing the amount of water needed by each animal in a zoo.\n",
    "\n",
    "Let's read this CSV file into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo_url = 'https://raw.githubusercontent.com/michaelschung/bc-data-processing/master/datasets/zoo.csv'\n",
    "\n",
    "zoo = pd.read_csv(zoo_url)\n",
    "zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to get an idea of what our DataFrame looks like but we don't want to report the entire thing, we can use `zoo.head()` to display the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass a number into `zoo.head()` to specify a specific number of rows to report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that currently, the index of our DataFrame is given by default integer values. However, in this case this is unnecessary, because every animal already has a unique ID number, specified in the `uniq_id` column.\n",
    "\n",
    "Instead, it would be better for the `animal` column to be the index, so that we can query for all elephants, all tigers, etc. We accomplish this using the `set_index()` method, which takes a column name as a specifier makes it the new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo = zoo.set_index('animal')\n",
    "zoo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note that `zoo.set_index('animal')` does not change the `zoo` DataFrame on its own. So to avoid making unnecessary copies, we are overwriting the previous `zoo` with its new copy with an updated index._\n",
    "\n",
    "An alternative way to set the index is to do so during the `read_csv` process. To accomplish this, we use an extra parameter `index_col` to tell Pandas ahead of time which column to use as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 0th column as the index\n",
    "zoo = pd.read_csv(zoo_url, index_col=0)\n",
    "zoo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying a DataFrame\n",
    "\n",
    "Let's say we want to find out which animals need more than 300 gallons of water. The column name for amount of water needed is `water_need`, so we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo['water_need'] > 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the format of the output here: we are given a Series consisting of a bunch of Booleans. We call this a **Boolean mask**, because we can use it to \"mask\" the results of the DataFrame.\n",
    "\n",
    "For example, perhaps we want to see _all_ of the information for each animal that requires more than 300 gallons of water. We can use our Boolean mask to query the DataFrame using the `where()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guzzlers = zoo.where(zoo['water_need'] > 300)\n",
    "guzzlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of that command as basically saying, \"Give me all of the rows in the DataFrame where the `water_need` column has a value greater than 300.\"\n",
    "\n",
    "You may notice that for every animal with a lower water  need, its entire row was filled with `NaN` (Python's abbreviation for \"not a number\"). That's okay! This is Pandas' way of telling you that those rows are not applicable given the query you just performed.\n",
    "\n",
    "These `NaN`s may look annoying and problematic, but Pandas knows to ignore them when it performs any further operations. We can show this by comparing the number of rows in the `water_need` column of `guzzlers` to the analogous number in our original table `zoo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(guzzlers.count())\n",
    "print(zoo.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, it'll usually be nicer to drop the `NaN` rows anyway, and we can do that using the `dropna()` method. Recall that the `drop()` method (discussed earlier) returns a copy of the original DataFrame. Similarly, `dropna()` by default also returns a copy, so we must include the parameter `inplace=True` to force `guzzlers` to apply the change to itself.\n",
    "\n",
    "_Alternatively, we could omit the extra parameter and just update `guzzlers` to the copy of itselfÂ - similar to what we did when we changed the index._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guzzlers.dropna(inplace=True)\n",
    "guzzlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's summarize. To query specific rows from a DataFrame, we need to:\n",
    "\n",
    "1. Create a Boolean mask based on column values in question\n",
    "2. Pass this mask into the `where()` function of the DataFrame\n",
    "3. Remove `NaN` rows using `dropna()`\n",
    "\n",
    "Let's try one more example together. Write a query for all animals that have ID numbers greater than or equal to 1010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = zoo['uniq_id'] >= 1010\n",
    "newbies = zoo.where(mask)\n",
    "newbies.dropna(inplace=True)\n",
    "newbies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Querying\n",
    "\n",
    "## Shorthand queries\n",
    "\n",
    "Now that you've mastered the pattern of querying, it's time you know that there's actually a faster way. Querying for a specific subset and dropping the `NaN` rows is such a common set of actions that Pandas provies a shorthand way to do it. All we need to do is to query the DataFrame directly, using a Boolean mask instead of an index label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo[zoo['water_need'] > 300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks confusing, think of it this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask\n",
    "mask = zoo['water_need'] > 300\n",
    "# Use the mask to query the DataFrame directly\n",
    "zoo[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Boolean masks\n",
    "\n",
    "We can combine multiple Boolean masks to accomplish more complex queries.\n",
    "\n",
    "Previously, we queried to see which animals require more than 300 gallons of water, as well as which have ID numbers greater than or equal to 1010. Now, let's query for which animals fulfill both of those at the same time. We can do this by combining the two masks using the `&` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_mask = zoo['water_need'] > 300\n",
    "id_mask = zoo['uniq_id'] >= 1010\n",
    "mask = water_mask & id_mask\n",
    "newbie_guzzlers = zoo[mask]\n",
    "newbie_guzzlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, all of that code can be condensed into one single line.\n",
    "\n",
    "**Note: when Boolean masks are combined inline like this, each mask _must_ be encased in parentheses.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parentheses around each Boolean mask!\n",
    "newbie_guzzlers = zoo[(zoo['water_need'] > 300) & (zoo['uniq_id'] >= 1010)]\n",
    "newbie_guzzlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write a query that finds all animals with ID numbers less than 1014, which also require less than 250 gallons of water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo[(zoo['uniq_id'] < 1014) & (zoo['water_need'] < 250)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final exercise, write a query that finds all animals with ID numbers from 1010-1019, and also require between 200-399 gallons of water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_mask = (zoo['uniq_id'] >= 1010) & (zoo['uniq_id'] < 1020)\n",
    "water_mask = (zoo['water_need'] >= 200) & (zoo['water_need'] < 400)\n",
    "mask = id_mask & water_mask\n",
    "zoo[mask]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
